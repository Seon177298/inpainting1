{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from bldcsag512_SD15 import *\n",
    "\n",
    "\n",
    "# - device는 SAM과 BLDCSAG768의 device를 다르게 설정해주세요.\n",
    "SAM_device = 'cuda:2'\n",
    "BLDCSAG_device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original 이미지 받아서 마스크 바로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file prefix (can be: heel1, heel2, bag1, bottle1, car1, cup1, perfume1, perfume2)\n",
    "file_prefix = \"heel1\"\n",
    "background = \"white\"\n",
    "\n",
    "# Define base paths\n",
    "base_path = \"/home/ada6k4_01/inpainting\"\n",
    "ori_path = f\"{base_path}/file_ori_obj\"\n",
    "mask_path = f\"{base_path}/files_mask1\"\n",
    "canny_path = f\"{base_path}/canny\"\n",
    "\n",
    "# Define target size\n",
    "target_size = (512, 512)\n",
    "\n",
    "# Read and resize original image\n",
    "img = Image.open(f\"{ori_path}/{file_prefix}_white.png\")\n",
    "img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "img_resized.save(f\"{ori_path}/resize_512/{file_prefix}_white.png\")\n",
    "\n",
    "# Read and resize mask\n",
    "mask = create_mask(\n",
    "    image_path=f\"{mask_path}/{file_prefix}_mask.png\",\n",
    "    output_path=f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "    threshold=0,\n",
    ")\n",
    "\n",
    "mask = Image.open(f\"{mask_path}/invert/{file_prefix}_mask1.png\")\n",
    "mask_resized = mask.resize(target_size, Image.Resampling.LANCZOS)\n",
    "mask_resized.save(f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\")\n",
    "\n",
    "# Convert canny image to PIL and resize\n",
    "canny_image = create_canny_mask(\n",
    "    image_path=f\"{ori_path}/{file_prefix}_white.png\",\n",
    "    output_path=f\"{canny_path}/{file_prefix}_canny1.png\",\n",
    "    low_threshold=50,\n",
    "    high_threshold=250,\n",
    ")\n",
    "canny_pil = Image.fromarray(canny_image)\n",
    "canny_resized = canny_pil.resize(target_size, Image.Resampling.LANCZOS)\n",
    "canny_resized.save(f\"{canny_path}/resize/{file_prefix}_canny1.png\")\n",
    "\n",
    "plt.imshow(img_resized)\n",
    "plt.title(\"Image Resized\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask_resized, cmap='gray')\n",
    "plt.title(\"Mask Resized\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(canny_resized, cmap='gray')\n",
    "plt.title(\"Canny Resized\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 ## : BLDCSAG1024로 output image 생성\n",
    "# - Generation time : 75~85s(w/.SAG), 50~60s(w/o.SAG) / GPU Memory Usage : 8500~9500MiB\n",
    "# - prompt와 negative_prompt는1 자유롭게 변경하면서 사용해주세요.\n",
    "# - output_col과 output_row는 output image의 개수와 출력 형태를 결정합니다.\n",
    "# - blending_start_percentage에 따라 blending 과정을 얼마나 빠르게 시작할지 결정됩니다. (Default : 0.1, Recommend : [0.1,0.4])\n",
    "# - kernel_size는 object outline에서 artifact 발견시 크기를 늘려주세요. (Default : 1, Recommend : [1,3])\n",
    "# - num_inference_steps는 model이 inference 과정에서 진행할 sampling step입니다. (Default : 100, Recommend : [70,150])\n",
    "# - guidance_scale는 prompt와 negative_prompt를 사용한 CFG Guidance scale 입니다. (Default : 7.0, Recommend : [7.0,7.5])\n",
    "# - sag_scale은 SAG Guidance scale입니다. (Default : 0.6, Recommend : [0.6,0.8], SAG 미사용 시 0.0으로 설정해주시면 됩니다.)\n",
    "# - seed는 None일 경우 random한 image가 generation됩니다.\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"prompt\": \"A heel at a stylish rooftop bar in New York City at night, offering a breathtaking view of the city's iconic skyline.\",\n",
    "    \"negative_prompt\": \"high heel, person, human hand, human hair, human face, human arm, human leg, human body, handle mug, duplicates, duplicate, blurry, bokeh, cropped, deformed, error, lowres, jpeg artifacts, low resolution, low quality, cartoonish, drawing, water painting, painting, illustration\",\n",
    "    \"output_col\": 1,\n",
    "    \"output_row\": 1,\n",
    "    \"blending_start_percentage\": 0.1,\n",
    "    \"kernel_size\": 1,  # Default : 1\n",
    "    \"num_inference_steps\": 50,  # Default : 50\n",
    "    \"guidance_scale\": 7.0,  # Default : 7.0\n",
    "    \"sag_scale\": 0.6,  # Default : 0.6\n",
    "    # \"seed\": random.randint(1, 2147483647),  # random.randint(1, 2147483647)   # Default : 0\n",
    "    \"seed\": 1891752616,\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "# - 주석처리된 부분은 참고용 input으로, 실제 input이 아니므로 주석해제하시면 오류 발생합니다.\n",
    "bld_controlnet = BLDCSAG512(\n",
    "    prompt=parameters[\"prompt\"],\n",
    "    negative_prompt=parameters[\"negative_prompt\"],\n",
    "    init_image=f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "    mask=f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "    # model_path='stabilityai/stable-diffusion-2-1',\n",
    "    # controlnet_model_path='thibaud/controlnet-sd21-canny-diffusers',  # ControlNet SD 2.1 Canny model path\n",
    "    blending_start_percentage=parameters[\"blending_start_percentage\"],\n",
    "    device=BLDCSAG_device,\n",
    "    batch_size=parameters[\"output_col\"] * parameters[\"output_row\"],\n",
    "    # output_path='output.png'\n",
    ")\n",
    "results = bld_controlnet.edit_image(\n",
    "    kernel_size=parameters[\"kernel_size\"],\n",
    "    num_inference_steps=parameters[\"num_inference_steps\"],\n",
    "    guidance_scale=parameters[\"guidance_scale\"],\n",
    "    sag_scale=parameters[\"sag_scale\"],\n",
    "    seed=parameters[\"seed\"],\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "parameters[\"generation_time\"] = elapsed_time\n",
    "\n",
    "image_saver = ImageGridSaver(\n",
    "    results,\n",
    "    parameters[\"output_col\"],\n",
    "    parameters[\"output_row\"],\n",
    "    bld_controlnet.output_path,\n",
    ")\n",
    "image_saver.save_grid()\n",
    "\n",
    "img_display = ImageGridDisplay(\n",
    "    f\"{ori_path}/resize_512/{file_prefix}_{background}.png\", \n",
    "    f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "    f\"{canny_path}/resize/{file_prefix}_canny1.png\", \n",
    "    results[0])\n",
    "img_display.display()\n",
    "\n",
    "table = ParametersTable(parameters)\n",
    "table.display_table()\n",
    "print(f'random seed: {parameters[\"seed\"]}')\n",
    "\n",
    "# evaluator = ImageQualityEvaluator(output_path='output.png', mask_path='mask.png', original_path='image.png')\n",
    "# evaluator.show_metrics_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메모리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Current GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Max GPU memory allocated: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Current GPU memory reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "        print(f\"Max GPU memory reserved: {torch.cuda.max_memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한 번에 여러 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from bldcsag512_SD15 import *\n",
    "\n",
    "\n",
    "# - device는 SAM과 BLDCSAG768의 device를 다르게 설정해주세요.\n",
    "SAM_device = 'cuda:2'\n",
    "BLDCSAG_device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복할 배경색 리스트 정의\n",
    "backgrounds = [\"white\", \"blue\", \"green\", \"red\"]\n",
    "\n",
    "for background in backgrounds:\n",
    "    # Define file prefix (can be: heel1, heel2, bag1, bottle1, car1, cup1, perfume1, perfume2)\n",
    "    object_prefix = \"perfume\"\n",
    "    file_prefix = f\"{object_prefix}1\"\n",
    "\n",
    "    # Define base paths\n",
    "    base_path = \"/home/ada6k4_01/inpainting\"\n",
    "    ori_path = f\"{base_path}/file_ori_obj\"\n",
    "    mask_path = f\"{base_path}/files_mask1\"\n",
    "    canny_path = f\"{base_path}/canny\"\n",
    "\n",
    "    # Define target size\n",
    "    target_size = (512, 512)\n",
    "\n",
    "    # Read and resize original image\n",
    "    img = Image.open(f\"{ori_path}/{file_prefix}_{background}.png\")\n",
    "    img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    img_resized.save(f\"{ori_path}/resize_512/{file_prefix}_{background}.png\")\n",
    "\n",
    "    # Read and resize mask\n",
    "    mask = create_mask(\n",
    "        image_path=f\"{mask_path}/{file_prefix}_mask.png\",\n",
    "        output_path=f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "        use_otsu=True,\n",
    "        inver_mask=False,\n",
    "        normalize=False,\n",
    "    )\n",
    "\n",
    "    mask = Image.open(f\"{mask_path}/invert/{file_prefix}_mask1.png\")\n",
    "    mask_resized = mask.resize(target_size, Image.Resampling.NEAREST)\n",
    "    mask_resized.save(f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\")\n",
    "\n",
    "    # Convert canny image to PIL and resize\n",
    "    canny_image = create_canny_mask(\n",
    "        image_path=f\"{ori_path}/{file_prefix}_{background}.png\",\n",
    "        output_path=f\"{canny_path}/{file_prefix}_canny1.png\",\n",
    "        low_threshold=50,\n",
    "        high_threshold=250,\n",
    "    )\n",
    "    canny_pil = Image.fromarray(canny_image)\n",
    "    canny_resized = canny_pil.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    canny_resized.save(f\"{canny_path}/resize/{file_prefix}_canny1.png\")\n",
    "\n",
    "    parameters = {\n",
    "        \"prompt\": f\"A {object_prefix} is displayed on a rustic cobblestone street, with soft evening lantern light creating a cozy, nostalgic ambiance.\",\n",
    "        \"negative_prompt\": \"person, human hand, human hair, human face, human arm, human leg, human body, handle mug, duplicates, duplicate, blurry, bokeh, cropped, deformed, error, lowres, jpeg artifacts, low resolution, low quality, cartoonish, drawing, water painting, painting, illustration\",\n",
    "        \"output_col\": 1,\n",
    "        \"output_row\": 1,\n",
    "        \"blending_start_percentage\": 0.1,\n",
    "        \"kernel_size\": 3,\n",
    "        \"num_inference_steps\": 50,\n",
    "        \"guidance_scale\": 7.0,\n",
    "        \"sag_scale\": 0.0,\n",
    "        \"seed\": 354572332,\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    bld_controlnet = BLDCSAG512(\n",
    "        prompt=parameters[\"prompt\"],\n",
    "        negative_prompt=parameters[\"negative_prompt\"],\n",
    "        init_image=f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "        mask=f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",\n",
    "        blending_start_percentage=parameters[\"blending_start_percentage\"],\n",
    "        device=BLDCSAG_device,\n",
    "        batch_size=parameters[\"output_col\"] * parameters[\"output_row\"],\n",
    "        output_path=f\"output_{background}.png\",  # 배경색별 output 파일명 지정\n",
    "    )\n",
    "    \n",
    "\n",
    "    results = bld_controlnet.edit_image(\n",
    "        kernel_size=parameters[\"kernel_size\"],\n",
    "        num_inference_steps=parameters[\"num_inference_steps\"],\n",
    "        guidance_scale=parameters[\"guidance_scale\"],\n",
    "        sag_scale=parameters[\"sag_scale\"],\n",
    "        seed=parameters[\"seed\"],\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    parameters[\"generation_time\"] = elapsed_time\n",
    "\n",
    "    # Save results\n",
    "    image_saver = ImageGridSaver(\n",
    "        results,\n",
    "        parameters[\"output_col\"],\n",
    "        parameters[\"output_row\"],\n",
    "        bld_controlnet.output_path,\n",
    "    )\n",
    "    image_saver.save_grid()\n",
    "\n",
    "    # Display results\n",
    "    img_display = ImageGridDisplay(\n",
    "        f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "        f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",\n",
    "        f\"{canny_path}/resize/{file_prefix}_canny1.png\",\n",
    "        results[0],\n",
    "    )\n",
    "    img_display.display()\n",
    "\n",
    "    # Display parameters\n",
    "    table = ParametersTable(parameters)\n",
    "    table.display_table()\n",
    "    print(f\"Background: {background}\")\n",
    "    print(f'Random seed: {parameters[\"seed\"]}')\n",
    "    print(\"=\" * 50)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러 object 여러 background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from bldcsag512_SD15 import *\n",
    "\n",
    "\n",
    "# - device는 SAM과 BLDCSAG768의 device를 다르게 설정해주세요.\n",
    "SAM_device = 'cuda:2'\n",
    "BLDCSAG_device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복할 배경색 리스트 정의\n",
    "backgrounds = [\"white\", \"blue\", \"green\", \"red\"]\n",
    "# Define objects list with their prefixes\n",
    "objects = [\"heel1\", \"heel2\", \"bag1\", \"bottle1\", \"car1\", \"cup1\", \"perfume1\", \"perfume2\"]\n",
    "\n",
    "for object_prefix in objects:\n",
    "    for background in backgrounds:\n",
    "        # Define file prefix\n",
    "        file_prefix = object_prefix\n",
    "\n",
    "        # Define base paths\n",
    "        base_path = \"/home/ada6k4_01/inpainting\"\n",
    "        ori_path = f\"{base_path}/file_ori_obj\"\n",
    "        mask_path = f\"{base_path}/files_mask1\"\n",
    "        canny_path = f\"{base_path}/canny\"\n",
    "\n",
    "        # Define target size\n",
    "        target_size = (512, 512)\n",
    "\n",
    "        # Read and resize original image\n",
    "        img = Image.open(f\"{ori_path}/{file_prefix}_{background}.png\")\n",
    "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        img_resized.save(f\"{ori_path}/resize_512/{file_prefix}_{background}.png\")\n",
    "\n",
    "        # Read and resize mask\n",
    "        mask = create_mask(\n",
    "            image_path=f\"{mask_path}/{file_prefix}_mask.png\",\n",
    "            output_path=f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "            use_otsu=True,\n",
    "            inver_mask=False,\n",
    "            normalize=False,\n",
    "        )\n",
    "\n",
    "        mask = Image.open(f\"{mask_path}/invert/{file_prefix}_mask1.png\")\n",
    "        mask_resized = mask.resize(target_size, Image.Resampling.NEAREST)\n",
    "        mask_resized.save(f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\")\n",
    "\n",
    "        # Convert canny image to PIL and resize\n",
    "        canny_image = create_canny_mask(\n",
    "            image_path=f\"{ori_path}/{file_prefix}_{background}.png\",\n",
    "            output_path=f\"{canny_path}/{file_prefix}_canny1.png\",\n",
    "            low_threshold=50,\n",
    "            high_threshold=250,\n",
    "        )\n",
    "        canny_pil = Image.fromarray(canny_image)\n",
    "        canny_resized = canny_pil.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        canny_resized.save(f\"{canny_path}/resize/{file_prefix}_canny1.png\")\n",
    "\n",
    "        # Customize prompt based on object type\n",
    "        object_type = object_prefix.rstrip('123')  # Remove numbers from object name\n",
    "        parameters = {\n",
    "            \"prompt\": f\"A {object_type} is displayed on a rustic cobblestone street, with soft evening lantern light creating a cozy, nostalgic ambiance.\",\n",
    "            \"negative_prompt\": \"person, human hand, human hair, human face, human arm, human leg, human body, handle mug, duplicates, duplicate, blurry, bokeh, cropped, deformed, error, lowres, jpeg artifacts, low resolution, low quality, cartoonish, drawing, water painting, painting, illustration\",\n",
    "            \"output_col\": 1,\n",
    "            \"output_row\": 1,\n",
    "            \"blending_start_percentage\": 0.1,\n",
    "            \"kernel_size\": 7,\n",
    "            \"num_inference_steps\": 50,\n",
    "            \"guidance_scale\": 7.0,\n",
    "            \"sag_scale\": 0.0,\n",
    "            \"seed\": 354572332,\n",
    "        }\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        bld_controlnet = BLDCSAG512(\n",
    "            prompt=parameters[\"prompt\"],\n",
    "            negative_prompt=parameters[\"negative_prompt\"],\n",
    "            init_image=f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "            mask=f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",  # 배경색별 output 파일명 지정\n",
    "            blending_start_percentage=parameters[\"blending_start_percentage\"],\n",
    "            device=BLDCSAG_device,\n",
    "            batch_size=parameters[\"output_col\"] * parameters[\"output_row\"],\n",
    "            output_path=f\"/home/ada6k4_01/inpainting/output/output_{object_prefix}_{background}.png\",  # Include object prefix in output filename\n",
    "        )\n",
    "\n",
    "        results = bld_controlnet.edit_image(\n",
    "            kernel_size=parameters[\"kernel_size\"],\n",
    "            num_inference_steps=parameters[\"num_inference_steps\"],\n",
    "            guidance_scale=parameters[\"guidance_scale\"],\n",
    "            sag_scale=parameters[\"sag_scale\"],\n",
    "            seed=parameters[\"seed\"],\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        parameters[\"generation_time\"] = elapsed_time\n",
    "\n",
    "        # Save results\n",
    "        image_saver = ImageGridSaver(\n",
    "            results,\n",
    "            parameters[\"output_col\"],\n",
    "            parameters[\"output_row\"],\n",
    "            bld_controlnet.output_path,\n",
    "        )\n",
    "        image_saver.save_grid()\n",
    "\n",
    "        # Display results\n",
    "        img_display = ImageGridDisplay(\n",
    "            f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "            f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",\n",
    "            f\"{canny_path}/resize/{file_prefix}_canny1.png\",\n",
    "            results[0],\n",
    "        )\n",
    "        img_display.display()\n",
    "\n",
    "        # Display parameters\n",
    "        # table = ParametersTable(parameters)\n",
    "        # table.display_table()\n",
    "        # print(f\"Object: {object_prefix}\")\n",
    "        # print(f\"Background: {background}\")\n",
    "        # print(f'Random seed: {parameters[\"seed\"]}')\n",
    "        # print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3 ## : BLDCSAG1024로 output image 생성\n",
    "# # - Generation time : 75~85s(w/.SAG), 50~60s(w/o.SAG) / GPU Memory Usage : 8500~9500MiB\n",
    "# # - prompt와 negative_prompt는 자유롭게 변경하면서 사용해주세요.\n",
    "# # - output_col과 output_row는 output image의 개수와 출력 형태를 결정합니다.\n",
    "# # - blending_start_percentage에 따라 blending 과정을 얼마나 빠르게 시작할지 결정됩니다. (Default : 0.1, Recommend : [0.1,0.4])\n",
    "# # - kernel_size는 object outline에서 artifact 발견시 크기를 늘려주세요. (Default : 1, Recommend : [1,3])\n",
    "# # - num_inference_steps는 model이 inference 과정에서 진행할 sampling step입니다. (Default : 100, Recommend : [70,150])\n",
    "# # - guidance_scale는 prompt와 negative_prompt를 사용한 CFG Guidance scale 입니다. (Default : 7.0, Recommend : [7.0,7.5])\n",
    "# # - sag_scale은 SAG Guidance scale입니다. (Default : 0.6, Recommend : [0.6,0.8], SAG 미사용 시 0.0으로 설정해주시면 됩니다.)\n",
    "# # - seed는 None일 경우 random한 image가 generation됩니다.\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     \"prompt\": \"A heel at a stylish rooftop bar in New York City at night, offering a breathtaking view of the city's iconic skyline.\",\n",
    "#     \"negative_prompt\": \"person, human hand, human hair, human face, human arm, human leg, human body, handle mug, duplicates, duplicate, blurry, bokeh, cropped, deformed, error, lowres, jpeg artifacts, low resolution, low quality, cartoonish, drawing, water painting, painting, illustration\",\n",
    "#     \"output_col\": 1,\n",
    "#     \"output_row\": 1,\n",
    "#     \"blending_start_percentage\": 0.1,\n",
    "#     \"kernel_size\": 1,  # Default : 1\n",
    "#     \"num_inference_steps\": 50,  # Default : 50\n",
    "#     \"guidance_scale\": 7.0,  # Default : 7.0\n",
    "#     \"sag_scale\": 0.6,  # Default : 0.6\n",
    "#     \"seed\": random.randint(1, 2147483647),  # random.randint(1, 2147483647)   # Default : 0\n",
    "#     # \"seed\": 1446565216,\n",
    "# }\n",
    "\n",
    "# start_time = time.time()\n",
    "# # - 주석처리된 부분은 참고용 input으로, 실제 input이 아니므로 주석해제하시면 오류 발생합니다.\n",
    "# bld_controlnet = BLDCSAGXL(\n",
    "#     prompt=parameters[\"prompt\"],\n",
    "#     negative_prompt=parameters[\"negative_prompt\"],\n",
    "#     # init_image='image.png',\n",
    "#     # mask='mask.png',\n",
    "#     # model_path='stabilityai/stable-diffusion-2-1',\n",
    "#     # controlnet_model_path='thibaud/controlnet-sd21-canny-diffusers',  # ControlNet SD 2.1 Canny model path\n",
    "#     blending_start_percentage=parameters[\"blending_start_percentage\"],\n",
    "#     device=BLDCSAG_device,\n",
    "#     batch_size=parameters[\"output_col\"] * parameters[\"output_row\"],\n",
    "#     # output_path='output.png'\n",
    "# )\n",
    "# results = bld_controlnet.edit_image(\n",
    "#     kernel_size=parameters[\"kernel_size\"],\n",
    "#     num_inference_steps=parameters[\"num_inference_steps\"],\n",
    "#     guidance_scale=parameters[\"guidance_scale\"],\n",
    "#     # sag_scale=parameters[\"sag_scale\"],\n",
    "#     seed=parameters[\"seed\"],\n",
    "# )\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# parameters[\"generation_time\"] = elapsed_time\n",
    "\n",
    "# image_saver = ImageGridSaver(\n",
    "#     results,\n",
    "#     parameters[\"output_col\"],\n",
    "#     parameters[\"output_row\"],\n",
    "#     bld_controlnet.output_path,\n",
    "# )\n",
    "# image_saver.save_grid()\n",
    "\n",
    "# img_display = ImageGridDisplay(\"image1.png\", \"mask1.png\", \"canny.png\", results[0])\n",
    "# img_display.display()\n",
    "\n",
    "# table = ParametersTable(parameters)\n",
    "# table.display_table()\n",
    "# print(f'random seed: {parameters[\"seed\"]}')\n",
    "\n",
    "# # evaluator = ImageQualityEvaluator(output_path='output.png', mask_path='mask.png', original_path='image.png')\n",
    "# # evaluator.show_metrics_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel 여러개 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ada6k4_01/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:Found CUDA without GPU_NUM_DEVICES. Defaulting to PJRT_DEVICE=CUDA with GPU_NUM_DEVICES=4\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/segment_anything_hq/modeling/tiny_vit_sam.py:662: UserWarning: Overwriting tiny_vit_5m_224 in registry with segment_anything_hq.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/segment_anything_hq/modeling/tiny_vit_sam.py:662: UserWarning: Overwriting tiny_vit_11m_224 in registry with segment_anything_hq.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/segment_anything_hq/modeling/tiny_vit_sam.py:662: UserWarning: Overwriting tiny_vit_21m_224 in registry with segment_anything_hq.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/segment_anything_hq/modeling/tiny_vit_sam.py:662: UserWarning: Overwriting tiny_vit_21m_384 in registry with segment_anything_hq.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/home/ada6k4_01/anaconda3/envs/venv/lib/python3.10/site-packages/segment_anything_hq/modeling/tiny_vit_sam.py:662: UserWarning: Overwriting tiny_vit_21m_512 in registry with segment_anything_hq.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from bldcsag512_SD15 import *\n",
    "\n",
    "\n",
    "# - device는 SAM과 BLDCSAG768의 device를 다르게 설정해주세요.\n",
    "SAM_device = 'cuda:2'\n",
    "BLDCSAG_device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_white_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_blue_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_green_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_red_3.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_heel2_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bag1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_bottle1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_car1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_cup1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume1_red_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_white_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_blue_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_green_5.png에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 /home/ada6k4_01/inpainting/output/output_perfume2_red_5.png에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 반복할 배경색 리스트 정의\n",
    "backgrounds = [\"white\", \"blue\", \"green\", \"red\"]\n",
    "# Define objects list with their prefixes\n",
    "objects = [\"heel1\", \"heel2\", \"bag1\", \"bottle1\", \"car1\", \"cup1\", \"perfume1\", \"perfume2\"]\n",
    "kernel_sizes = [3, 5]\n",
    "\n",
    "for kernel_size in kernel_sizes:\n",
    "    for object_prefix in objects:\n",
    "        for background in backgrounds:\n",
    "            # Define file prefix\n",
    "            file_prefix = object_prefix\n",
    "\n",
    "            # Define base paths\n",
    "            base_path = \"/home/ada6k4_01/inpainting\"\n",
    "            ori_path = f\"{base_path}/file_ori_obj\"\n",
    "            mask_path = f\"{base_path}/files_mask1\"\n",
    "            canny_path = f\"{base_path}/canny\"\n",
    "\n",
    "            # Define target size\n",
    "            target_size = (512, 512)\n",
    "\n",
    "            # Read and resize original image\n",
    "            img = Image.open(f\"{ori_path}/{file_prefix}_{background}.png\")\n",
    "            img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "            img_resized.save(f\"{ori_path}/resize_512/{file_prefix}_{background}.png\")\n",
    "\n",
    "            # Read and resize mask\n",
    "            mask = create_mask(\n",
    "                image_path=f\"{mask_path}/{file_prefix}_mask.png\",\n",
    "                output_path=f\"{mask_path}/invert/{file_prefix}_mask1.png\",\n",
    "                use_otsu=True,\n",
    "                inver_mask=False,\n",
    "                normalize=False,\n",
    "            )\n",
    "\n",
    "            mask = Image.open(f\"{mask_path}/invert/{file_prefix}_mask1.png\")\n",
    "            mask_resized = mask.resize(target_size, Image.Resampling.NEAREST)\n",
    "            mask_resized.save(f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\")\n",
    "\n",
    "            # Convert canny image to PIL and resize\n",
    "            canny_image = create_canny_mask(\n",
    "                image_path=f\"{ori_path}/{file_prefix}_{background}.png\",\n",
    "                output_path=f\"{canny_path}/{file_prefix}_canny1.png\",\n",
    "                low_threshold=50,\n",
    "                high_threshold=250,\n",
    "            )\n",
    "            canny_pil = Image.fromarray(canny_image)\n",
    "            canny_resized = canny_pil.resize(target_size, Image.Resampling.LANCZOS)\n",
    "            canny_resized.save(f\"{canny_path}/resize/{file_prefix}_canny1.png\")\n",
    "\n",
    "            # Customize prompt based on object type\n",
    "            object_type = object_prefix.rstrip('123')  # Remove numbers from object name\n",
    "            parameters = {\n",
    "                \"prompt\": f\"A {object_type} is displayed on a rustic cobblestone street, with soft evening lantern light creating a cozy, nostalgic ambiance.\",\n",
    "                \"negative_prompt\": \"person, human hand, human hair, human face, human arm, human leg, human body, handle mug, duplicates, duplicate, blurry, bokeh, cropped, deformed, error, lowres, jpeg artifacts, low resolution, low quality, cartoonish, drawing, water painting, painting, illustration\",\n",
    "                \"output_col\": 1,\n",
    "                \"output_row\": 1,\n",
    "                \"blending_start_percentage\": 0.1,\n",
    "                \"kernel_size\": kernel_size,  # Using the current kernel size from the loop\n",
    "                \"num_inference_steps\": 50,\n",
    "                \"guidance_scale\": 7.0,\n",
    "                \"sag_scale\": 0.0,\n",
    "                \"seed\": 354572332,\n",
    "            }\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            bld_controlnet = BLDCSAG512(\n",
    "                prompt=parameters[\"prompt\"],\n",
    "                negative_prompt=parameters[\"negative_prompt\"],\n",
    "                init_image=f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "                mask=f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",\n",
    "                blending_start_percentage=parameters[\"blending_start_percentage\"],\n",
    "                device=BLDCSAG_device,\n",
    "                batch_size=parameters[\"output_col\"] * parameters[\"output_row\"],\n",
    "                output_path=f\"/home/ada6k4_01/inpainting/output/output_{object_prefix}_{background}_{kernel_size}.png\",  # Modified to include kernel size\n",
    "            )\n",
    "\n",
    "            results = bld_controlnet.edit_image(\n",
    "                kernel_size=parameters[\"kernel_size\"],\n",
    "                num_inference_steps=parameters[\"num_inference_steps\"],\n",
    "                guidance_scale=parameters[\"guidance_scale\"],\n",
    "                sag_scale=parameters[\"sag_scale\"],\n",
    "                seed=parameters[\"seed\"],\n",
    "            )\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            parameters[\"generation_time\"] = elapsed_time\n",
    "\n",
    "            # Save results\n",
    "            image_saver = ImageGridSaver(\n",
    "                results,\n",
    "                parameters[\"output_col\"],\n",
    "                parameters[\"output_row\"],\n",
    "                bld_controlnet.output_path,\n",
    "            )\n",
    "            image_saver.save_grid()\n",
    "\n",
    "            # Display results\n",
    "            # img_display = ImageGridDisplay(\n",
    "            #     f\"{ori_path}/resize_512/{file_prefix}_{background}.png\",\n",
    "            #     f\"{mask_path}/real_mask_resize/{file_prefix}_mask1.png\",\n",
    "            #     f\"{canny_path}/resize/{file_prefix}_canny1.png\",\n",
    "            #     results[0],\n",
    "            # )\n",
    "            # img_display.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIPAway 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from step2 import *\n",
    "# ## 1 ## Mask generation을 위한 coord 확인\n",
    "# output_image_path = \"/home/ada6k4_01/inpainting/output.png\"\n",
    "# image_grid = ImageGrid(output_image_path)\n",
    "# image_grid.draw_grid()  \n",
    "\n",
    "# # - coord는 (x1, y1, x2, y2)로 값 순서를 반드시 지켜주세요. (Default: (2,2,14,14))\n",
    "# img_processor = SamHQImageProcessor_CLIPAway(\n",
    "#     img_path=output_image_path, \n",
    "#     device = SAM_device, \n",
    "#     coord=coord_fixed, \n",
    "#     mask_prefix='mask2', \n",
    "#     image_prefix='image2',\n",
    "#     mask_threshold=0.95,\n",
    "#     )\n",
    "# img_processor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 확장된 영역에서의 마스크 생성\n",
    "\n",
    "# mask1 = np.array(Image.open(\"mask1.png\"))\n",
    "# mask2 = np.array(Image.open(\"mask2.png\"))\n",
    "# print(\"Mask1 Size:\", mask1.shape)\n",
    "# print(\"Mask2 Size:\", mask2.shape)\n",
    "# plt.imshow(mask2, cmap='gray')\n",
    "# plt.show()\n",
    "# mask_expansion = get_expansion_area_mask(\"mask1.png\", \"mask2.png\")\n",
    "# plt.imshow(mask_expansion, cmap='gray')\n",
    "# plt.title(\"Expanded Mask Area\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확장 마스크 부분만 다시 CLIPAway 적용\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
